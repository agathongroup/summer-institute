---
title: "Collecting Digital Trace Data"
author: "Ahmet Kurnaz"
date: "30 05 2021"
output: slidy_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T,eval = F)
```

## Task 1 and 2

In this task we are going to learn to collect data by using an API and web scraping.

- Twitter API with *rtweet* package
- Academic Twitter *without a package*
- Eksisozluk public data with *rvest*
- Instagram public groups data with *RSelenium* package
- Facebook public groups data with *RSelenium* package

At the end of each small task we are going to create a structured dataset and save these datasets in different filetypes such as rds, csv etc.


## Twitter API and rtweet - What is it?

What is an API: [here](https://www.youtube.com/watch?v=s7wmiS2mSXY)

What is Twitter API: [here](https://developer.twitter.com/en/products/twitter-api)

What is rtweet package: [here](https://cran.r-project.org/web/packages/rtweet/)

## Twitter API and rtweet - Credentials

- Find your credentials: [here](https://developer.twitter.com/en/portal/dashboard) 
- Create an application: [here](https://developer.twitter.com/en/portal/projects-and-apps)
- Copy your credentials:
```{r twitter_credentials}
require(rtweet)

tw_api_key <-  'xxxxxxxxxxxx'
tw_api_secret <-  'xxxxxxxxxxxx'


tw_access_token <-  'xxxxxxxxxxxx'
tw_access_secret <- 'xxxxxxxxxxxx'

```
- Handshake

```{r tw_handshake}

my_tok <- create_token(
  app = "xxxxxxxxxxxxx",
  consumer_key = tw_api_key,
  consumer_secret = tw_api_secret,
  access_token = tw_access_token,
  access_secret = tw_access_secret)

```

## Twitter API and rtweet - Search Tweets

```{r tw_search}
require(data.table)

my_tweets <- rtweet::search_tweets(q = 'data science',n=100,token = my_tok)
my_tweets <- as.data.table(my_tweets)


summary(my_tweets)

my_tweets[,.N,by=screen_name][order(-N)]

my_tweets[!is.na(geo_coords)]

my_tweets[,.N,by=is_retweet]

my_tweets[like(text,'science')]

my_tweets[like(text,'science')&is_retweet==F]

```

## Twitter API and rtweet - Lookup Users


```{r tw_lookup_users}

my_users <- c("YildizzTilbee",'tarkan','haluklevent')

singer_tweeters <- lookup_users(my_users,token = my_tok)

singer_tweeters <- as.data.table(singer_tweeters)

tweets_data(singer_tweeters)

yildiz_tw_last <- rtweet::get_timeline(singer_tweeters[,user_id][1],n = 10,token = my_tok)

```


## Twitter API and rtweet  - Search Friends and Followers

```{r tw_fr_fol}

yildiz_followers <- rtweet::get_followers(singer_tweeters[,user_id][1],n = 10,token = my_tok)
tarkan_friends <- rtweet::get_friends(singer_tweeters[,user_id][2],n = 10,token = my_tok)


tarkan_friends_details <- rtweet::lookup_users(tarkan_friends$user_id,token = my_tok)
yildiz_followers_details <- rtweet::lookup_users(yildiz_followers$user_id,token = my_tok)

```

## Twitter API and rtweet - Rate Limits

API v1.1: [here](https://developer.twitter.com/en/docs/twitter-api/v1/rate-limits)
API v2: [here](https://developer.twitter.com/en/docs/twitter-api/rate-limits)

```{r tw_rate}

my_tweets <- rtweet::search_tweets(q = 'data science',n=100,token = my_tok,retryonratelimit = T)


```


## Academic Twitter without a package - 1

```{r tw_ac}
require(jsonlite)
require(httr)
require(data.table)
user_name='cnn'
n=10
q <- GET(url = paste0('https://api.twitter.com/2/tweets/search/all?query=from%3A',
                      user_name,
                      '&max_results=',n,
                      '&tweet.fields=attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld&user.fields=created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld&place.fields=contained_within,country,country_code,full_name,geo,id,name,place_type&media.fields=duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics'),
         add_headers(Authorization='Bearer AAAAAAAAAAAAAAAAAAAAAFyEMQEAAAAAbBcS70q67ndDEIvhS1hOnS4ZabQ%3D6Cfem1pc6s3eJgymOeHPUOXGrBp3XFCZAeLpVcC9vzYwc8S1vN'))  

content <- rawToChar(q$content)

content <- fromJSON(content)

```

## Academic Twitter without a package - 2

```{r tw_ac_se}

search_term='siyaset%20lang%3Atr'
n=100


q <- GET(url = paste0('https://api.twitter.com/2/tweets/search/all?query=',
                      search_term,
                      '&max_results=',n,
                      '&tweet.fields=attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld&user.fields=created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld&place.fields=contained_within,country,country_code,full_name,geo,id,name,place_type&media.fields=duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics'),
         add_headers(Authorization='Bearer AAAAAAAAAAAAAAAAAAAAAFyEMQEAAAAAbBcS70q67ndDEIvhS1hOnS4ZabQ%3D6Cfem1pc6s3eJgymOeHPUOXGrBp3XFCZAeLpVcC9vzYwc8S1vN'))  

content <- rawToChar(q$content)
content <- fromJSON(content)
content$data

```


## Eksi Sozluk Public Data with rvest - 2

```{r ek_rv}

eksi_url <- 'https://eksisozluk.com/ogrenildiginde-ufku-iki-katina-cikaran-seyler--2593151?a=nice'

eksi_page <-  read_html(eksi_url)

eksi_entries <-  eksi_page%>%html_nodes('#entry-item-list')%>%html_nodes('li')%>%html_text()


```



## Instagram Public Data with RSelenium 

```{r inst}

require(RSelenium)
require(rvest)

fprof <- makeFirefoxProfile(list(permissions.default.image = 2L,
                                 browser.migration.version = 9999L))

rD <- rsDriver(browser = c("firefox"),port = 4445L, extraCapabilities = fprof)
remDr <- rD$client

remDr$navigate('https://www.instagram.com/tarkan')


tarkan_page <- read_html(remDr$getPageSource()[[1]])

tarkan_page%>%html_nodes('div img')

```




## Facebook Public Data with RSelenium 

```{r fac}

require(RSelenium)
require(rvest)

fprof <- makeFirefoxProfile(list(permissions.default.image = 2L,
                                 browser.migration.version = 9999L))

rD <- rsDriver(browser = c("firefox"),port = 4445L, extraCapabilities = fprof)
remDr <- rD$client

remDr$navigate('https://www.facebook.com/groups/753303308656863')


webElem <- remDr$findElement("css", "body")
webElem$sendKeysToElement(list(key = "end"))

vaccine_page <- read_html(remDr$getPageSource()[[1]])

vaccine_nodes <- vaccine_page%>%html_nodes(xpath = '/html/body/div[1]/div/div[1]/div/div[3]/div/div/div[1]/div[1]/div[4]/div/div/div/div/div[1]/div[2]')%>%
  html_nodes('.du4w35lb')%>%html_node('div')%>%html_text()

vaccine_nodes <- vaccine_nodes[!is.na(vaccine_nodes)]

vaccine_nodes <- vaccine_nodes[vaccine_nodes!='']
vaccine_nodes <- vaccine_nodes[vaccine_nodes!='Beğen']
vaccine_nodes <- vaccine_nodes[vaccine_nodes!='Yorum Yap']
vaccine_nodes <- vaccine_nodes[vaccine_nodes!='Paylaş']
vaccine_nodes <- vaccine_nodes[vaccine_nodes%like%'bir soru sordu']

rD$server$stop()

```


